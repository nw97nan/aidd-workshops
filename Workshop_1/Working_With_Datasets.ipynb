{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "socSJe925zFv"
   },
   "source": [
    "#  Working With Datasets\n",
    "\n",
    "Data is central to machine learning.  This tutorial introduces the `Dataset` class that DeepChem uses to store and manage data.  It provides simple but powerful tools for efficiently working with large amounts of data.  It also is designed to easily interact with other popular Python frameworks such as NumPy, Pandas, TensorFlow, and PyTorch.\n",
    "\n",
    "## Colab\n",
    "\n",
    "This tutorial and the rest in this sequence can be done in Google colab. If you'd like to open this notebook in colab, you can use the following link.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepchem/deepchem/blob/master/examples/tutorials/Working_With_Datasets.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "CMWAv-Z46nCc",
    "outputId": "9ae7cfd0-ebbf-40b0-f6f1-2940cf32a839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepchem\n",
      "  Downloading deepchem-2.6.0.dev20220112042427-py3-none-any.whl (608 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.5/608.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib (from deepchem)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy in /Users/nan/miniconda3/envs/deepchem/lib/python3.11/site-packages (from deepchem) (1.26.3)\n",
      "Requirement already satisfied: pandas in /Users/nan/miniconda3/envs/deepchem/lib/python3.11/site-packages (from deepchem) (2.1.4)\n",
      "Collecting scikit-learn (from deepchem)\n",
      "  Downloading scikit_learn-1.4.0rc1-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy in /Users/nan/miniconda3/envs/deepchem/lib/python3.11/site-packages (from deepchem) (1.11.4)\n",
      "Collecting rdkit-pypi (from deepchem)\n",
      "  Downloading rdkit_pypi-2023.3.1b1-cp311-cp311-macosx_11_0_arm64.whl (23.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.3/23.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/nan/miniconda3/envs/deepchem/lib/python3.11/site-packages (from pandas->deepchem) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nan/miniconda3/envs/deepchem/lib/python3.11/site-packages (from pandas->deepchem) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/nan/miniconda3/envs/deepchem/lib/python3.11/site-packages (from pandas->deepchem) (2023.4)\n",
      "Collecting Pillow (from rdkit-pypi->deepchem)\n",
      "  Using cached pillow-10.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->deepchem)\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nan/miniconda3/envs/deepchem/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.16.0)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Downloading scikit_learn-1.4.0rc1-cp311-cp311-macosx_12_0_arm64.whl (10.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Downloading pillow-10.2.0-cp311-cp311-macosx_11_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, Pillow, joblib, scikit-learn, rdkit-pypi, deepchem\n",
      "Successfully installed Pillow-10.2.0 deepchem-2.6.0.dev20220112042427 joblib-1.3.2 rdkit-pypi-2023.3.1b1 scikit-learn-1.4.0rc1 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --pre deepchem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jk47QTZ95zF-"
   },
   "source": [
    "We can now import the `deepchem` package to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PDiY03h35zF_",
    "outputId": "cdd7401d-19a0-4476-9297-b04defc67178"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nan/miniconda3/envs/deepchem/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.7.2.dev'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "dc.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B0u7qIZd5zGG"
   },
   "source": [
    "# Anatomy of a Dataset\n",
    "\n",
    "In the last tutorial we loaded the Delaney dataset of molecular solubilities.  Let's load it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "saTaOpXY5zGI"
   },
   "outputs": [],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='GraphConv')\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F922OPtL5zGM"
   },
   "source": [
    "We now have three Dataset objects: the training, validation, and test sets.  What information does each of them contain?  We can start to get an idea by printing out the string representation of one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "YEDcUsz35zGO",
    "outputId": "5a05747f-8b06-407d-9b11-790a1b4d1c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DiskDataset X.shape: (113,), y.shape: (113, 1), w.shape: (113, 1), ids: ['c1cc2ccc3cccc4ccc(c1)c2c34' 'Cc1cc(=O)[nH]c(=S)[nH]1'\n",
      " 'Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4 ' ...\n",
      " 'c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43' 'Cc1occc1C(=O)Nc2ccccc2'\n",
      " 'OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)C(O)C3O '], task_names: ['measured log solubility in mols per litre']>\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E8UCFrrN5zGf"
   },
   "source": [
    "There's a lot of information there, so let's start at the beginning.  It begins with the label \"DiskDataset\".  Dataset is an abstract class.  It has a few subclasses that correspond to different ways of storing data.\n",
    "\n",
    "- `DiskDataset` is a dataset that has been saved to disk.  The data is stored in a way that can be efficiently accessed, even if the total amount of data is far larger than your computer's memory.\n",
    "- `NumpyDataset` is an in-memory dataset that holds all the data in NumPy arrays.  It is a useful tool when manipulating small to medium sized datasets that can fit entirely in memory.\n",
    "- `ImageDataset` is a more specialized class that stores some or all of the data in image files on disk.  It is useful when working with models that have images as their inputs or outputs.\n",
    "\n",
    "Now let's consider the contents of the Dataset.  Every Dataset stores a list of *samples*.  Very roughly speaking, a sample is a single data point.  In this case, each sample is a molecule.  In other datasets a sample might correspond to an experimental assay, a cell line, an image, or many other things.  For every sample the dataset stores the following information.\n",
    "\n",
    "- The *features*, referred to as `X`.  This is the input that should be fed into a model to represent the sample.\n",
    "- The *labels*, referred to as `y`.  This is the desired output from the model.  During training, it tries to make the model's output for each sample as close as possible to `y`.\n",
    "- The *weights*, referred to as `w`.  This can be used to indicate that some data values are more important than others.  In later tutorials we will see examples of how this is useful.\n",
    "- An *ID*, which is a unique identifier for the sample.  This can be anything as long as it is unique.  Sometimes it is just an integer index, but in this dataset the ID is a SMILES string describing the molecule.\n",
    "\n",
    "Notice that `X`, `y`, and `w` all have 113 as the size of their first dimension.  That means this dataset contains 113 samples.\n",
    "\n",
    "The final piece of information listed in the output is `task_names`.  Some datasets contain multiple pieces of information for each sample.  For example, if a sample represents a molecule, the dataset might record the results of several different experiments on that molecule.  This dataset has only a single task: \"measured log solubility in mols per litre\".  Also notice that `y` and `w` each have shape (113, 1).  The second dimension of these arrays usually matches the number of tasks.\n",
    "\n",
    "# Accessing Data from a Dataset\n",
    "\n",
    "There are many ways to access the data contained in a dataset.  The simplest is just to directly access the `X`, `y`, `w`, and `ids` properties.  Each of these returns the corresponding information as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5K3rdGV5zGg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.60114461],\n",
       "       [ 0.20848251],\n",
       "       [-0.01602738],\n",
       "       [-2.82191713],\n",
       "       [-0.52891635],\n",
       "       [ 1.10168349],\n",
       "       [-0.88987406],\n",
       "       [-0.52649706],\n",
       "       [-0.76358725],\n",
       "       [-0.64020358],\n",
       "       [-0.38569452],\n",
       "       [-0.62568785],\n",
       "       [-0.39585553],\n",
       "       [-2.05306753],\n",
       "       [-0.29666474],\n",
       "       [-0.73213651],\n",
       "       [-1.27744393],\n",
       "       [ 0.0081655 ],\n",
       "       [ 0.97588054],\n",
       "       [-0.10796031],\n",
       "       [ 0.59847167],\n",
       "       [-0.60149498],\n",
       "       [-0.34988907],\n",
       "       [ 0.34686576],\n",
       "       [ 0.62750312],\n",
       "       [ 0.14848418],\n",
       "       [ 0.02268122],\n",
       "       [-0.85310089],\n",
       "       [-2.72079091],\n",
       "       [ 0.42476682],\n",
       "       [ 0.01300407],\n",
       "       [-2.4851523 ],\n",
       "       [-2.15516147],\n",
       "       [ 1.00975056],\n",
       "       [ 0.82588471],\n",
       "       [-0.90390593],\n",
       "       [-0.91067993],\n",
       "       [-0.82455329],\n",
       "       [ 1.26909819],\n",
       "       [-1.14825397],\n",
       "       [-2.1343556 ],\n",
       "       [-1.15744727],\n",
       "       [-0.1045733 ],\n",
       "       [ 0.53073162],\n",
       "       [-1.22567118],\n",
       "       [-1.66452995],\n",
       "       [ 0.24525568],\n",
       "       [-0.13215318],\n",
       "       [-0.97067826],\n",
       "       [-0.23376326],\n",
       "       [ 1.21297072],\n",
       "       [-1.2595412 ],\n",
       "       [ 0.49686159],\n",
       "       [ 0.22396595],\n",
       "       [-0.44182199],\n",
       "       [ 0.47895886],\n",
       "       [ 0.08267956],\n",
       "       [-1.51840498],\n",
       "       [-0.34795364],\n",
       "       [-0.83858516],\n",
       "       [-0.13699176],\n",
       "       [-2.59498796],\n",
       "       [ 0.13106531],\n",
       "       [ 0.09042128],\n",
       "       [ 1.18877785],\n",
       "       [-0.82697258],\n",
       "       [-1.16857599],\n",
       "       [ 0.37589721],\n",
       "       [-0.24344041],\n",
       "       [-2.00952036],\n",
       "       [-0.59181783],\n",
       "       [-0.15634606],\n",
       "       [-2.87272217],\n",
       "       [-0.34069577],\n",
       "       [ 0.27622256],\n",
       "       [-2.15467761],\n",
       "       [-0.02812382],\n",
       "       [-2.77401524],\n",
       "       [ 0.25638441],\n",
       "       [ 0.84040043],\n",
       "       [-0.86277804],\n",
       "       [-1.52082426],\n",
       "       [ 0.29702844],\n",
       "       [ 0.44363727],\n",
       "       [ 0.47460415],\n",
       "       [-0.08376743],\n",
       "       [ 0.68556602],\n",
       "       [ 0.79201468],\n",
       "       [-1.2401869 ],\n",
       "       [ 0.6129874 ],\n",
       "       [-0.58214068],\n",
       "       [-1.51598569],\n",
       "       [-1.93984487],\n",
       "       [-0.30295489],\n",
       "       [-0.24827899],\n",
       "       [ 1.06442646],\n",
       "       [-1.48259952],\n",
       "       [ 0.0275198 ],\n",
       "       [ 0.33718861],\n",
       "       [-0.91600236],\n",
       "       [ 0.58637523],\n",
       "       [-0.62084928],\n",
       "       [-0.30827732],\n",
       "       [-1.95145746],\n",
       "       [-0.83568202],\n",
       "       [ 0.10977558],\n",
       "       [ 1.90488697],\n",
       "       [-0.75149081],\n",
       "       [-1.65630437],\n",
       "       [ 0.74362893],\n",
       "       [-2.42079925],\n",
       "       [-0.20957039],\n",
       "       [ 1.01458914]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Zcd7jTd5zGr"
   },
   "source": [
    "This is a very easy way to access data, but you should be very careful about using it.  This requires the data for all samples to be loaded into memory at once.  That's fine for small datasets like this one, but for large datasets it could easily take more memory than you have.\n",
    "\n",
    "A better approach is to iterate over the dataset.  That lets it load just a little data at a time, process it, then free the memory before loading the next bit.  You can use the `itersamples()` method to iterate over samples one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LJc90fs_5zGs",
    "outputId": "8c9fd5ab-e23a-40dc-9292-8b4ff3a86890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.60114461] c1cc2ccc3cccc4ccc(c1)c2c34\n",
      "[0.20848251] Cc1cc(=O)[nH]c(=S)[nH]1\n",
      "[-0.01602738] Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4 \n",
      "[-2.82191713] c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45\n",
      "[-0.52891635] C1=Cc2cccc3cccc1c23\n",
      "[1.10168349] CC1CO1\n",
      "[-0.88987406] CCN2c1ccccc1N(C)C(=S)c3cccnc23 \n",
      "[-0.52649706] CC12CCC3C(CCc4cc(O)ccc34)C2CCC1=O\n",
      "[-0.76358725] Cn2cc(c1ccccc1)c(=O)c(c2)c3cccc(c3)C(F)(F)F\n",
      "[-0.64020358] ClC(Cl)(Cl)C(NC=O)N1C=CN(C=C1)C(NC=O)C(Cl)(Cl)Cl \n",
      "[-0.38569452] COc2c1occc1cc3ccc(=O)oc23 \n",
      "[-0.62568785] CN2C(=C(O)c1ccccc1S2(=O)=O)C(=O)Nc3ccccn3 \n",
      "[-0.39585553] Cc3cc2nc1c(=O)[nH]c(=O)nc1n(CC(O)C(O)C(O)CO)c2cc3C\n",
      "[-2.05306753] c1ccc(cc1)c2ccc(cc2)c3ccccc3\n",
      "[-0.29666474] CC34CC(=O)C1C(CCC2=CC(=O)CCC12C)C3CCC4(=O) \n",
      "[-0.73213651] c1ccc2c(c1)sc3ccccc23\n",
      "[-1.27744393] CC23Cc1cnoc1C=C2CCC4C3CCC5(C)C4CCC5(O)C#C\n",
      "[0.0081655] OC(C(=O)c1ccccc1)c2ccccc2\n",
      "[0.97588054] OCC2OC(Oc1ccccc1CO)C(O)C(O)C2O\n",
      "[-0.10796031] CC3C2CCC1(C)C=CC(=O)C(=C1C2OC3=O)C\n",
      "[0.59847167] O=Cc2ccc1OCOc1c2 \n",
      "[-0.60149498] CC1CCCCC1NC(=O)Nc2ccccc2\n",
      "[-0.34988907] CC(=O)N(S(=O)c1ccc(N)cc1)c2onc(C)c2C \n",
      "[0.34686576] C1N(C(=O)NCC(C)C)C(=O)NC1\n",
      "[0.62750312] CNC(=O)Oc1ccccc1C2OCCO2\n",
      "[0.14848418] CC1=C(CCCO1)C(=O)Nc2ccccc2 \n",
      "[0.02268122] Cn2c(=O)on(c1ccc(Cl)c(Cl)c1)c2=O\n",
      "[-0.85310089] C1Cc2cccc3cccc1c23\n",
      "[-2.72079091] c1ccc2cc3c4cccc5cccc(c3cc2c1)c45\n",
      "[0.42476682] Nc1cc(nc(N)n1=O)N2CCCCC2 \n",
      "[0.01300407] O=c2c(C3CCCc4ccccc43)c(O)c1ccccc1o2 \n",
      "[-2.4851523] CC(C)C(Nc1ccc(cc1Cl)C(F)(F)F)C(=O)OC(C#N)c2cccc(Oc3ccccc3)c2\n",
      "[-2.15516147] Cc1c(F)c(F)c(COC(=O)C2C(C=C(Cl)C(F)(F)F)C2(C)C)c(F)c1F\n",
      "[1.00975056] c2ccc1[nH]nnc1c2\n",
      "[0.82588471] c2ccc1ocnc1c2\n",
      "[-0.90390593] CCOC(=O)c1cncn1C(C)c2ccccc2\n",
      "[-0.91067993] CCN2c1ccccc1N(C)C(=O)c3ccccc23 \n",
      "[-0.82455329] OCC(O)COC(=O)c1ccccc1Nc2ccnc3cc(Cl)ccc23\n",
      "[1.26909819] OCC1OC(OC2C(O)C(O)C(O)OC2CO)C(O)C(O)C1O\n",
      "[-1.14825397] CC34CCc1c(ccc2cc(O)ccc12)C3CCC4=O\n",
      "[-2.1343556] ClC1=C(Cl)C(Cl)(C(=C1Cl)Cl)C2(Cl)C(=C(Cl)C(=C2Cl)Cl)Cl\n",
      "[-1.15744727] ClC1(C(=O)C2(Cl)C3(Cl)C14Cl)C5(Cl)C2(Cl)C3(Cl)C(Cl)(Cl)C45Cl\n",
      "[-0.1045733] Oc1ccc(c(O)c1)c3oc2cc(O)cc(O)c2c(=O)c3O \n",
      "[0.53073162] C1SC(=S)NC1(=O)\n",
      "[-1.22567118] ClC(Cl)C(Cl)(Cl)SN2C(=O)C1CC=CCC1C2=O \n",
      "[-1.66452995] ClC1=C(Cl)C2(Cl)C3C4CC(C=C4)C3C1(Cl)C2(Cl)Cl\n",
      "[0.24525568] CC(=O)Nc1nnc(s1)S(N)(=O)=O \n",
      "[-0.13215318] CC1=C(SCCO1)C(=O)Nc2ccccc2\n",
      "[-0.97067826] CN(C(=O)COc1nc2ccccc2s1)c3ccccc3\n",
      "[-0.23376326] CN(C(=O)NC(C)(C)c1ccccc1)c2ccccc2\n",
      "[1.21297072] Nc1nccs1 \n",
      "[-1.2595412] CN(C=Nc1ccc(C)cc1C)C=Nc2ccc(C)cc2C\n",
      "[0.49686159] OCC(O)C2OC1OC(OC1C2O)C(Cl)(Cl)Cl \n",
      "[0.22396595] Nc3nc(N)c2nc(c1ccccc1)c(N)nc2n3\n",
      "[-0.44182199] CC2Nc1cc(Cl)c(cc1C(=O)N2c3ccccc3C)S(N)(=O)=O \n",
      "[0.47895886] CN1CC(O)N(C1=O)c2nnc(s2)C(C)(C)C\n",
      "[0.08267956] CCC1(C(=O)NC(=O)NC1=O)C2=CCC3CCC2C3\n",
      "[-1.51840498] CCC(C)C(=O)OC2CC(C)C=C3C=CC(C)C(CCC1CC(O)CC(=O)O1)C23 \n",
      "[-0.34795364] CC2Cc1ccccc1N2NC(=O)c3ccc(Cl)c(c3)S(N)(=O)=O \n",
      "[-0.83858516] o1c2ccccc2c3ccccc13\n",
      "[-0.13699176] O=C(Nc1ccccc1)Nc2ccccc2\n",
      "[-2.59498796] c1ccc2c(c1)c3cccc4c3c2cc5ccccc54\n",
      "[0.13106531] COc1ccc(cc1)C(O)(C2CC2)c3cncnc3 \n",
      "[0.09042128] c1cnc2c(c1)ccc3ncccc23\n",
      "[1.18877785] OCC1OC(CO)(OC2OC(COC3OC(CO)C(O)C(O)C3O)C(O)C(O)C2O)C(O)C1O\n",
      "[-0.82697258] CCOC(=O)c1ccccc1S(=O)(=O)NN(C=O)c2nc(Cl)cc(OC)n2\n",
      "[-1.16857599] CC34CCC1C(=CCc2cc(O)ccc12)C3CCC4=O\n",
      "[0.37589721] CN(C)C(=O)Oc1cc(C)nn1c2ccccc2\n",
      "[-0.24344041] OC(Cn1cncn1)(c2ccc(F)cc2)c3ccccc3F\n",
      "[-2.00952036] Cc1c2ccccc2c(C)c3ccc4ccccc4c13\n",
      "[-0.59181783] Cc3nnc4CN=C(c1ccccc1Cl)c2cc(Cl)ccc2n34\n",
      "[-0.15634606] Cc3ccnc4N(C1CC1)c2ncccc2C(=O)Nc34 \n",
      "[-2.87272217] c1cc2cccc3c4cccc5cccc(c(c1)c23)c54\n",
      "[-0.34069577] COc1cc(cc(OC)c1O)C6C2C(COC2=O)C(OC4OC3COC(C)OC3C(O)C4O)c7cc5OCOc5cc67\n",
      "[0.27622256] O=c1[nH]cnc2nc[nH]c12 \n",
      "[-2.15467761] C1C(O)CCC2(C)CC3CCC4(C)C5(C)CC6OCC(C)CC6OC5CC4C3C=C21\n",
      "[-0.02812382] Cc1ccccc1n3c(C)nc2ccccc2c3=O\n",
      "[-2.77401524] CCOc1ccc(cc1)C(C)(C)COCc3cccc(Oc2ccccc2)c3\n",
      "[0.25638441] CCC1(CCC(=O)NC1=O)c2ccccc2 \n",
      "[0.84040043] CC1CC(C)C(=O)C(C1)C(O)CC2CC(=O)NC(=O)C2 \n",
      "[-0.86277804] CC(=O)C3CCC4C2CC=C1CC(O)CCC1(C)C2CCC34C \n",
      "[-1.52082426] Cc1ccc(OP(=O)(Oc2cccc(C)c2)Oc3ccccc3C)cc1\n",
      "[0.29702844] CSc1nnc(c(=O)n1N)C(C)(C)C\n",
      "[0.44363727] Nc1ncnc2n(ccc12)C3OC(CO)C(O)C3O \n",
      "[0.47460415] O=C2NC(=O)C1(CC1)C(=O)N2 \n",
      "[-0.08376743] C1Cc2ccccc2C1\n",
      "[0.68556602] c1ccc2cnccc2c1\n",
      "[0.79201468] OCC1OC(C(O)C1O)n2cnc3c(O)ncnc23\n",
      "[-1.2401869] c2(Cl)c(Cl)c(Cl)c1nccnc1c2(Cl) \n",
      "[0.6129874] C1OC1c2ccccc2 \n",
      "[-0.58214068] CCC(=C(CC)c1ccc(O)cc1)c2ccc(O)cc2 \n",
      "[-1.51598569] c1ccc2c(c1)c3cccc4cccc2c34\n",
      "[-1.93984487] CC(C)C(C(=O)OC(C#N)c1cccc(Oc2ccccc2)c1)c3ccc(OC(F)F)cc3\n",
      "[-0.30295489] CCCC1COC(Cn2cncn2)(O1)c3ccc(Cl)cc3Cl\n",
      "[-0.24827899] O=C2CN(N=Cc1ccc(o1)N(=O)=O)C(=O)N2 \n",
      "[1.06442646] NC(=O)c1cnccn1\n",
      "[-1.48259952] OC4=C(C1CCC(CC1)c2ccc(Cl)cc2)C(=O)c3ccccc3C4=O\n",
      "[0.0275198] O=C(Cn1ccnc1N(=O)=O)NCc2ccccc2\n",
      "[0.33718861] CCC1(C(=O)NC(=O)NC1=O)C2=CCCCC2 \n",
      "[-0.91600236] COC(=O)C1=C(C)NC(=C(C1c2ccccc2N(=O)=O)C(=O)OC)C \n",
      "[0.58637523] O=C2NC(=O)C1(CCC1)C(=O)N2\n",
      "[-0.62084928] CCCOP(=S)(OCCC)SCC(=O)N1CCCCC1C\n",
      "[-0.30827732] N(c1ccccc1)c2ccccc2\n",
      "[-1.95145746] ClC(Cl)=C(c1ccc(Cl)cc1)c2ccc(Cl)cc2\n",
      "[-0.83568202] O=c2[nH]c1CCCc1c(=O)n2C3CCCCC3\n",
      "[0.10977558] CCC1(C(=O)NCNC1=O)c2ccccc2\n",
      "[1.90488697] O=C1CCCN1\n",
      "[-0.75149081] COc5cc4OCC3Oc2c1CC(Oc1ccc2C(=O)C3c4cc5OC)C(C)=C \n",
      "[-1.65630437] ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl\n",
      "[0.74362893] c1ccsc1\n",
      "[-2.42079925] c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43\n",
      "[-0.20957039] Cc1occc1C(=O)Nc2ccccc2\n",
      "[1.01458914] OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)C(O)C3O \n"
     ]
    }
   ],
   "source": [
    "for X, y, w, id in test_dataset.itersamples():\n",
    "    print(y, id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQa88cbj5zGw"
   },
   "source": [
    "Most deep learning models can process a batch of multiple samples all at once.  You can use `iterbatches()` to iterate over batches of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "HSVqeYox5zGx",
    "outputId": "270a6a17-6238-4081-b0cf-3f17e23f4bb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1)\n",
      "(50, 1)\n",
      "(13, 1)\n"
     ]
    }
   ],
   "source": [
    "for X, y, w, ids in test_dataset.iterbatches(batch_size=50):\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iterbatches()` has other features that are useful when training models.  For example, `iterbatches(batch_size=100, epochs=10, deterministic=False)` will iterate over the complete dataset ten times, each time with the samples in a different random order.\n",
    "\n",
    "Datasets can also expose data using the standard interfaces for TensorFlow and PyTorch.  To get a `tensorflow.data.Dataset`, call `make_tf_dataset()`.  To get a `torch.utils.data.IterableDataset`, call `make_pytorch_dataset()`.  See the API documentation for more details.\n",
    "\n",
    "The final way of accessing data is `to_dataframe()`.  This copies the data into a Pandas `DataFrame`.  This requires storing all the data in memory at once, so you should only use it with small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
       "      <td>-1.601145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c1cc2ccc3cccc4ccc(c1)c2c34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
       "      <td>0.208483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cc1cc(=O)[nH]c(=S)[nH]1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
       "      <td>-0.016027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
       "      <td>-2.821917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
       "      <td>-0.528916</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C1=Cc2cccc3cccc1c23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
       "      <td>-1.656304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
       "      <td>0.743629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c1ccsc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
       "      <td>-2.420799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
       "      <td>-0.209570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cc1occc1C(=O)Nc2ccccc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>&lt;deepchem.feat.mol_graphs.ConvMol object at 0x...</td>\n",
       "      <td>1.014589</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     X         y    w  \\\n",
       "0    <deepchem.feat.mol_graphs.ConvMol object at 0x... -1.601145  1.0   \n",
       "1    <deepchem.feat.mol_graphs.ConvMol object at 0x...  0.208483  1.0   \n",
       "2    <deepchem.feat.mol_graphs.ConvMol object at 0x... -0.016027  1.0   \n",
       "3    <deepchem.feat.mol_graphs.ConvMol object at 0x... -2.821917  1.0   \n",
       "4    <deepchem.feat.mol_graphs.ConvMol object at 0x... -0.528916  1.0   \n",
       "..                                                 ...       ...  ...   \n",
       "108  <deepchem.feat.mol_graphs.ConvMol object at 0x... -1.656304  1.0   \n",
       "109  <deepchem.feat.mol_graphs.ConvMol object at 0x...  0.743629  1.0   \n",
       "110  <deepchem.feat.mol_graphs.ConvMol object at 0x... -2.420799  1.0   \n",
       "111  <deepchem.feat.mol_graphs.ConvMol object at 0x... -0.209570  1.0   \n",
       "112  <deepchem.feat.mol_graphs.ConvMol object at 0x...  1.014589  1.0   \n",
       "\n",
       "                                                   ids  \n",
       "0                           c1cc2ccc3cccc4ccc(c1)c2c34  \n",
       "1                              Cc1cc(=O)[nH]c(=S)[nH]1  \n",
       "2           Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4   \n",
       "3                     c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45  \n",
       "4                                  C1=Cc2cccc3cccc1c23  \n",
       "..                                                 ...  \n",
       "108     ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl  \n",
       "109                                            c1ccsc1  \n",
       "110                 c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43  \n",
       "111                             Cc1occc1C(=O)Nc2ccccc2  \n",
       "112  OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...  \n",
       "\n",
       "[113 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Datasets\n",
    "\n",
    "Now let's talk about how you can create your own datasets.  Creating a `NumpyDataset` is very simple: just pass the arrays containing the data to the constructor.  Let's create some random arrays, then wrap them in a NumpyDataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NumpyDataset X.shape: (10, 5), y.shape: (10, 2), w.shape: (10, 1), ids: [0 1 2 3 4 5 6 7 8 9], task_names: [0 1]>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.random((10, 5))\n",
    "y = np.random.random((10, 2))\n",
    "dataset = dc.data.NumpyDataset(X=X, y=y)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we did not specify weights or IDs.  These are optional, as is `y` for that matter.  Only `X` is required.  Since we left them out, it automatically built `w` and `ids` arrays for us, setting all weights to 1 and setting the IDs to integer indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>w</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.822703</td>\n",
       "      <td>0.772416</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.299826</td>\n",
       "      <td>0.284096</td>\n",
       "      <td>0.804178</td>\n",
       "      <td>0.971732</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019017</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>0.423337</td>\n",
       "      <td>0.037370</td>\n",
       "      <td>0.631214</td>\n",
       "      <td>0.489187</td>\n",
       "      <td>0.982022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.939769</td>\n",
       "      <td>0.443336</td>\n",
       "      <td>0.460325</td>\n",
       "      <td>0.647625</td>\n",
       "      <td>0.747809</td>\n",
       "      <td>0.636039</td>\n",
       "      <td>0.988776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.297808</td>\n",
       "      <td>0.705291</td>\n",
       "      <td>0.377177</td>\n",
       "      <td>0.748129</td>\n",
       "      <td>0.012841</td>\n",
       "      <td>0.814289</td>\n",
       "      <td>0.802613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.263643</td>\n",
       "      <td>0.856959</td>\n",
       "      <td>0.104696</td>\n",
       "      <td>0.339403</td>\n",
       "      <td>0.260783</td>\n",
       "      <td>0.789105</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.033981</td>\n",
       "      <td>0.231013</td>\n",
       "      <td>0.167157</td>\n",
       "      <td>0.716343</td>\n",
       "      <td>0.725669</td>\n",
       "      <td>0.067089</td>\n",
       "      <td>0.583135</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.766298</td>\n",
       "      <td>0.833166</td>\n",
       "      <td>0.640183</td>\n",
       "      <td>0.141227</td>\n",
       "      <td>0.918515</td>\n",
       "      <td>0.224123</td>\n",
       "      <td>0.645187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.122353</td>\n",
       "      <td>0.823358</td>\n",
       "      <td>0.258427</td>\n",
       "      <td>0.393292</td>\n",
       "      <td>0.586260</td>\n",
       "      <td>0.631972</td>\n",
       "      <td>0.523607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.809674</td>\n",
       "      <td>0.421554</td>\n",
       "      <td>0.269404</td>\n",
       "      <td>0.293783</td>\n",
       "      <td>0.209030</td>\n",
       "      <td>0.903598</td>\n",
       "      <td>0.633814</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.663656</td>\n",
       "      <td>0.429689</td>\n",
       "      <td>0.769111</td>\n",
       "      <td>0.833402</td>\n",
       "      <td>0.124632</td>\n",
       "      <td>0.299617</td>\n",
       "      <td>0.437287</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5        y1        y2    w  \\\n",
       "0  0.822703  0.772416  0.235000  0.299826  0.284096  0.804178  0.971732  1.0   \n",
       "1  0.019017  0.999341  0.423337  0.037370  0.631214  0.489187  0.982022  1.0   \n",
       "2  0.939769  0.443336  0.460325  0.647625  0.747809  0.636039  0.988776  1.0   \n",
       "3  0.297808  0.705291  0.377177  0.748129  0.012841  0.814289  0.802613  1.0   \n",
       "4  0.263643  0.856959  0.104696  0.339403  0.260783  0.789105  0.000839  1.0   \n",
       "5  0.033981  0.231013  0.167157  0.716343  0.725669  0.067089  0.583135  1.0   \n",
       "6  0.766298  0.833166  0.640183  0.141227  0.918515  0.224123  0.645187  1.0   \n",
       "7  0.122353  0.823358  0.258427  0.393292  0.586260  0.631972  0.523607  1.0   \n",
       "8  0.809674  0.421554  0.269404  0.293783  0.209030  0.903598  0.633814  1.0   \n",
       "9  0.663656  0.429689  0.769111  0.833402  0.124632  0.299617  0.437287  1.0   \n",
       "\n",
       "  ids  \n",
       "0   0  \n",
       "1   1  \n",
       "2   2  \n",
       "3   3  \n",
       "4   4  \n",
       "5   5  \n",
       "6   6  \n",
       "7   7  \n",
       "8   8  \n",
       "9   9  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about creating a DiskDataset?  If you have the data in NumPy arrays, you can call `DiskDataset.from_numpy()` to save it to disk.  Since this is just a tutorial, we will save it to a temporary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DiskDataset X.shape: (10, 5), y.shape: (10, 2), w.shape: (10, 1), ids: [0 1 2 3 4 5 6 7 8 9], task_names: [0 1]>\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as data_dir:\n",
    "    disk_dataset = dc.data.DiskDataset.from_numpy(X=X, y=y, data_dir=data_dir)\n",
    "    print(disk_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about larger datasets that can't fit in memory?  What if you have some huge files on disk containing data on hundreds of millions of molecules?  The process for creating a DiskDataset from them is slightly more involved.  Fortunately, DeepChem's `DataLoader` framework can automate most of the work for you.  That is a larger subject, so we will return to it in a later tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MhZxVoVs5zMa"
   },
   "source": [
    "# Congratulations! Time to join the Community!\n",
    "\n",
    "Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:\n",
    "\n",
    "## Star DeepChem on [GitHub](https://github.com/deepchem/deepchem)\n",
    "This helps build awareness of the DeepChem project and the tools for open source drug discovery that we're trying to build.\n",
    "\n",
    "## Join the DeepChem Gitter\n",
    "The DeepChem [Gitter](https://gitter.im/deepchem/Lobby) hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "01_The_Basic_Tools_of_the_Deep_Life_Sciences.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
